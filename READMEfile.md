# LLM-Based-Prompt-Tuning

An intelligent system for optimizing prompts using dual LLM architecture with automated evaluation and persistence.

## ğŸš€ Features

- **Dual-Model Architecture**: Uses two LLMs (mistral, llama2) for optimization
- **Advanced Prompt Engineering**: Role-based templates and context management
- **Comprehensive Evaluation**: BLEU, ROUGE, and semantic similarity metrics
- **Data Persistence**: SQLite-based storage for optimization results
- **Automated Testing**: Full test suite across different prompt categories
- **Performance Monitoring**: GPU usage and response time tracking

## ğŸ“‹ Prerequisites

- Python 3.12+
- [Ollama](https://ollama.ai/)
- CUDA-capable GPU (recommended)
- Linux environment

## ğŸ› ï¸ Installation

```bash
# Clone the repository
git clone <your-repo-url>
cd LLM_PROJECT

# Create and activate virtual environment
python -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Download required models
ollama pull mistral
ollama pull llama2
```

## ğŸ’» Usage

```bash
# Run the optimization pipeline
python src/optimization/pipeline.py

# Run evaluation and generate reports
python src/evaluation/evaluation_pipeline.py

# Run all tests
python -m unittest discover -v
```

## ğŸ“ Project Structure

```
LLM_PROJECT/
â”œâ”€â”€ config/           # Configuration files
â”œâ”€â”€ data/            # Data storage
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/      # Configuration management
â”‚   â”œâ”€â”€ data_persistence/
â”‚   â”œâ”€â”€ evaluation/  # Metrics & evaluation
â”‚   â”œâ”€â”€ logging/     # Performance monitoring
â”‚   â”œâ”€â”€ models/      # Model interfaces
â”‚   â””â”€â”€ optimization/# Core optimization
â””â”€â”€ tests/
    â”œâ”€â”€ integration/
    â”œâ”€â”€ prompt_suite/
    â””â”€â”€ unit/
```

## âš™ï¸ Configuration

Edit files in `config/`:
- `config.yaml`: Main configuration
- `templates.yaml`: Prompt templates

## ğŸ“Š Evaluation

Results are saved in:
- `evaluation_results.csv`
- `evaluation_results.md`

## ğŸ“– Documentation

See `docs/` for:
- Project roadmap
- Architecture decisions
- Performance benchmarks

## ğŸ§ª Testing

```bash
# Run specific test suites
python -m unittest tests/prompt_suite/test_prompt_categories.py
python -m unittest tests/integration/test_database.py
```

## ğŸ“œ License

[MIT](LICENSE)

## ğŸ¤ Contributing

Pull requests are welcome! Please open an issue first to discuss proposed changes.
